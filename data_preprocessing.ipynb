{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Basic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:22.885586Z",
     "start_time": "2020-04-05T09:23:18.860965Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:25.948182Z",
     "start_time": "2020-04-05T09:23:24.273789Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Code</th>\n",
       "      <th>fun1_code</th>\n",
       "      <th>fun2_code</th>\n",
       "      <th>jobname_ch</th>\n",
       "      <th>jobname_en</th>\n",
       "      <th>id</th>\n",
       "      <th>coname</th>\n",
       "      <th>poname</th>\n",
       "      <th>jd</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FUN</td>\n",
       "      <td>BRO</td>\n",
       "      <td>BRO</td>\n",
       "      <td>BRO</td>\n",
       "      <td>商业研究</td>\n",
       "      <td>Business Research</td>\n",
       "      <td>279011</td>\n",
       "      <td>Aldevron</td>\n",
       "      <td>Strategic Account Manager, Nucleic Acids Busin...</td>\n",
       "      <td>\\n\\nWe are currently seeking a Strategic Accou...</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUN</td>\n",
       "      <td>BRO</td>\n",
       "      <td>BRO</td>\n",
       "      <td>BRO</td>\n",
       "      <td>商业研究</td>\n",
       "      <td>Business Research</td>\n",
       "      <td>287601</td>\n",
       "      <td>Synergy America</td>\n",
       "      <td>IT Business Analyst</td>\n",
       "      <td>\\n\\nWe are looking for an IT Business Analyst ...</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FUN</td>\n",
       "      <td>BRO</td>\n",
       "      <td>BRO</td>\n",
       "      <td>BRO</td>\n",
       "      <td>商业研究</td>\n",
       "      <td>Business Research</td>\n",
       "      <td>340361</td>\n",
       "      <td>A3 Smart Home</td>\n",
       "      <td>Sr. Business Analyst</td>\n",
       "      <td>\\n\\nWe call our club's vision, mission, values...</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type Code fun1_code fun2_code jobname_ch         jobname_en      id  \\\n",
       "0  FUN  BRO       BRO       BRO       商业研究  Business Research  279011   \n",
       "1  FUN  BRO       BRO       BRO       商业研究  Business Research  287601   \n",
       "2  FUN  BRO       BRO       BRO       商业研究  Business Research  340361   \n",
       "\n",
       "            coname                                             poname  \\\n",
       "0         Aldevron  Strategic Account Manager, Nucleic Acids Busin...   \n",
       "1  Synergy America                                IT Business Analyst   \n",
       "2    A3 Smart Home                               Sr. Business Analyst   \n",
       "\n",
       "                                                  jd   source  \n",
       "0  \\n\\nWe are currently seeking a Strategic Accou...  monster  \n",
       "1  \\n\\nWe are looking for an IT Business Analyst ...  monster  \n",
       "2  \\n\\nWe call our club's vision, mission, values...  monster  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from local pathway\n",
    "\n",
    "project_path = \"/Users/apple/Documents/Xinzhi/Data/\"\n",
    "data = pd.read_csv(project_path + \"meta_training_data_jd_0401.csv\")\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:28.391472Z",
     "start_time": "2020-04-05T09:23:28.385961Z"
    }
   },
   "outputs": [],
   "source": [
    "# get stop words\n",
    "\n",
    "def get_stopwords(words_file):\n",
    "    stopwords = []\n",
    "    with open(words_file, 'r') as file:\n",
    "        for word in file.readlines():\n",
    "            stopwords.append(word.strip('\\n'))\n",
    "    \n",
    "    return stopwords\n",
    "\n",
    "\n",
    "stopwords = get_stopwords(\"stop_words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:31.889741Z",
     "start_time": "2020-04-05T09:23:31.881572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tier 1 job title:  97\n",
      "The number of tier 2 job title:  709\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of tier 1 job title: \", len(data.fun1_code.unique()))\n",
    "print(\"The number of tier 2 job title: \", len(data.Code.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:32.558460Z",
     "start_time": "2020-04-05T09:23:32.505588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>fun1_code</th>\n",
       "      <th>fun2_code</th>\n",
       "      <th>jobname_ch</th>\n",
       "      <th>jobname_en</th>\n",
       "      <th>id</th>\n",
       "      <th>coname</th>\n",
       "      <th>poname</th>\n",
       "      <th>jd</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFB080</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFY660</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AHR165</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMS900</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APM080</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APM900</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVO060</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNV</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YHF020</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type  fun1_code  fun2_code  jobname_ch  jobname_en  id  coname  \\\n",
       "Code                                                                     \n",
       "AFB080     1          1          1           1           1   1       1   \n",
       "AFY660     1          1          1           1           1   1       1   \n",
       "AHR165     1          1          1           1           1   1       1   \n",
       "AMS900     1          1          1           1           1   1       1   \n",
       "APM080     1          1          1           1           1   1       1   \n",
       "APM900     1          1          1           1           1   1       1   \n",
       "AVO060     1          1          1           1           1   1       1   \n",
       "BNV        1          1          1           1           1   1       1   \n",
       "YHF020     1          1          1           1           1   1       1   \n",
       "\n",
       "        poname  jd  source  \n",
       "Code                        \n",
       "AFB080       1   1       1  \n",
       "AFY660       1   1       1  \n",
       "AHR165       1   1       1  \n",
       "AMS900       1   1       1  \n",
       "APM080       1   1       1  \n",
       "APM900       1   1       1  \n",
       "AVO060       1   1       1  \n",
       "BNV          1   1       1  \n",
       "YHF020       1   1       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class 'Code' that only have 1 instance\n",
    "jd_count = data.groupby('Code').count()\n",
    "jd_count[jd_count['jd']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:37.167525Z",
     "start_time": "2020-04-05T09:23:37.162225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of jds\n",
    "jd_list = data.jd.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:48:28.137953Z",
     "start_time": "2020-04-04T16:48:28.134971Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_text\n",
    "\n",
    "jd1 = data.jd[20698]\n",
    "jd2 = data.jd[20798]\n",
    "test_jd = [jd1, jd2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:36:34.459630Z",
     "start_time": "2020-04-04T16:36:34.457494Z"
    }
   },
   "source": [
    "## 2 - Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Word segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:47.988759Z",
     "start_time": "2020-04-05T09:23:47.985477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test base: `text_to_word_sequence`\n",
    "def segment_text_list(text_list):\n",
    "    text_list_segmented = [text_to_word_sequence(text) for text in text_list]\n",
    "    \n",
    "    return text_list_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:23:56.849723Z",
     "start_time": "2020-04-05T09:23:56.841908Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextTokenizer():\n",
    "    def __init__(self, texts=None):\n",
    "        self.texts = texts   \n",
    "        self.tokenizer = Tokenizer()\n",
    "        if texts is not None:\n",
    "            self.tokenizer.fit_on_texts(texts)\n",
    "            \n",
    "#         tokenizer.word_counts\n",
    "#         tokenizer.word_docs\n",
    "#         tokenizer.word_index\n",
    "#         tokenizer.document_count\n",
    "        \n",
    "    def train(self, train_text):\n",
    "        self.tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "    def to_sequences(self, in_text=None):\n",
    "        if in_text is None:\n",
    "            return self.tokenizer.texts_to_sequences(self.texts)\n",
    "        else:\n",
    "            return self.tokenizer.texts_to_sequences(in_text)\n",
    "    \n",
    "    def max_length(self):\n",
    "        sequences = self.to_sequences()\n",
    "        lenth = []\n",
    "        for i in sequences:\n",
    "            lenth.append(len(i))\n",
    "        mx_lenth = max(lenth)\n",
    "        \n",
    "        print(lenth.index(mx_lenth), mx_lenth)\n",
    "    \n",
    "    \n",
    "    def max_length2(self):  \n",
    "        sequences = self.to_sequences()\n",
    "        lenth = 0\n",
    "        for i in sequences:\n",
    "            if len(i) > lenth:\n",
    "                lenth = len(i)\n",
    "                idx = sequences.index(i)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        print(idx, lenth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:24:05.453638Z",
     "start_time": "2020-04-05T09:24:05.450700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_count(text_list_segmented):\n",
    "    tk = TextTokenizer(text_list_segmented)\n",
    "    feature_count = len(tk.tokenizer.word_counts)\n",
    "    \n",
    "    return feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T05:05:52.991380Z",
     "start_time": "2020-04-04T05:05:52.986144Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T08:31:52.203524Z",
     "start_time": "2020-04-05T08:31:52.200651Z"
    }
   },
   "outputs": [],
   "source": [
    "test_2 = [\"Data science is an inter-disciplinary field to extract knowledge and insights from data.\",\n",
    "             \"Data science is _related to data mining and big data 666 555teststring.\",\n",
    "             \"Data science unifies statistics, __data analysis, and machine learning.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Correct misspelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:24:13.730870Z",
     "start_time": "2020-04-05T09:24:13.726816Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_unknown(text_list_segmented):\n",
    "    spell = SpellChecker()\n",
    "    unkonwn_words = [list(spell.unknown(word_list)) for word_list in text_list_segmented]\n",
    "    \n",
    "    return unkonwn_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:24:22.203817Z",
     "start_time": "2020-04-05T09:24:22.200575Z"
    }
   },
   "outputs": [],
   "source": [
    "def spell_correction(text_list_segmented):\n",
    "    spell = SpellChecker()\n",
    "    corrected = [[spell.correction(word) for word in word_list] for word_list in text_list_segmented]\n",
    "    \n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Keep pure words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:24:30.625079Z",
     "start_time": "2020-04-05T09:24:30.621043Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean the segmented text list, keep only pure english words        \n",
    "\n",
    "def keep_pure_text(text_list_segmented):\n",
    "    for word_list in text_list_segmented:\n",
    "        for word in word_list:\n",
    "            match = re.findall(r'^[a-z]+$', word)\n",
    "            if match:\n",
    "                pass\n",
    "            else: \n",
    "                word_list.remove(word)\n",
    "    \n",
    "    return text_list_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:24:39.088874Z",
     "start_time": "2020-04-05T09:24:39.085173Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_stopwords(text_list_segmented, stop_words):\n",
    "    filtered_words = [[word for word in word_list if word not in stop_words]\n",
    "                      for word_list in text_list_segmented]\n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:24:48.040553Z",
     "start_time": "2020-04-05T09:24:48.037370Z"
    }
   },
   "outputs": [],
   "source": [
    "def stemer_starter(stemmer, text_list_segmented):\n",
    "    result = [[stemmer.stem(word) for word in word_list] for word_list in text_list_segmented]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:24:56.343599Z",
     "start_time": "2020-04-05T09:24:56.340150Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_stem(stemmer, text_list_segmented):\n",
    "    print(\"Before stem: \", get_feature_count(text_list_segmented))\n",
    "    stemmed = stemer_starter(stemmer, text_list_segmented)\n",
    "    print(\"After stem: \", get_feature_count(stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:25:04.878870Z",
     "start_time": "2020-04-05T09:25:04.875077Z"
    }
   },
   "outputs": [],
   "source": [
    "stem_test_text = [['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "                   'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "                   'meeting', 'stating', 'siezing', 'itemization',\n",
    "                   'sensational', 'traditional', 'reference', 'colonizer',\n",
    "                   'plotted'],\n",
    "                  ['try', 'tries', 'tring', 'apple', 'apples', 'watch', 'watches',\n",
    "                   'teeth', 'tooth', 'foot', 'feet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:25:13.628732Z",
     "start_time": "2020-04-05T09:25:13.625764Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "ss = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:25:22.320569Z",
     "start_time": "2020-04-05T09:25:22.316544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['caress', 'fli', 'die', 'mule', 'deni', 'die', 'agre', 'own', 'humbl', 'size', 'meet', 'state', 'siez', 'item', 'sensat', 'tradit', 'refer', 'colon', 'plot'], ['tri', 'tri', 'tring', 'appl', 'appl', 'watch', 'watch', 'teeth', 'tooth', 'foot', 'feet']]\n"
     ]
    }
   ],
   "source": [
    "print(stemer_starter(ps, stem_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:25:30.574027Z",
     "start_time": "2020-04-05T09:25:30.569734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['caress', 'fli', 'die', 'mule', 'deni', 'die', 'agre', 'own', 'humbl', 'size', 'meet', 'state', 'siez', 'item', 'sensat', 'tradit', 'refer', 'colon', 'plot'], ['tri', 'tri', 'tring', 'appl', 'appl', 'watch', 'watch', 'teeth', 'tooth', 'foot', 'feet']]\n"
     ]
    }
   ],
   "source": [
    "print(stemer_starter(ss, stem_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:25:38.927854Z",
     "start_time": "2020-04-05T09:25:38.923189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stem:  30\n",
      "After stem:  26\n"
     ]
    }
   ],
   "source": [
    "test_stem(ss, stem_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T09:25:47.155792Z",
     "start_time": "2020-04-05T09:25:47.152008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stem:  30\n",
      "After stem:  26\n"
     ]
    }
   ],
   "source": [
    "test_stem(ps, stem_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.989px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
